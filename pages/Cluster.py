import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO


from sklearn.preprocessing import StandardScaler
from sklearn.cluster import (
    KMeans,
    DBSCAN,
    AgglomerativeClustering,
    Birch,
)
from sklearn.metrics import silhouette_score

import plotly.express as px

from function import addColumns  # âž¡ï¸ ÑƒÑ‚Ð¸Ð»Ñ–Ñ‚Ð¸ Ð· Visualize
import os

# ----------------------------------------------------------------------------
# âš™ï¸ ÐšÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ ÑÑ‚Ð¾Ñ€Ñ–Ð½ÐºÐ¸
# ----------------------------------------------------------------------------
st.set_page_config(page_title="ÐšÐ»Ð°ÑÑ‚ÐµÑ€Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð·", layout="wide")

st.title("ðŸ§© ÐšÐ»Ð°ÑÑ‚ÐµÑ€Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· ÑÐ¾Ð½ÑÑ‡Ð½Ð¸Ñ… ÑÐ¿Ð°Ð»Ð°Ñ…Ñ–Ð²")

# ----------------------------------------------------------------------------
# 1ï¸âƒ£ Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð´Ð°Ð½Ð¸Ñ…
# ----------------------------------------------------------------------------

def load_dataframe(src):
    """Ð§Ð¸Ñ‚Ð°Ð½Ð½Ñ CSV / Excel Ñ‡Ð¸ UploadedFile Ñƒ DataFrame (dtype=str)."""
    if isinstance(src, str):
        return pd.read_csv(src, dtype=str)
    ext = os.path.splitext(src.name)[-1].lower()
    if ext == ".xlsx":
        return pd.read_excel(src, dtype=str)
    return pd.read_csv(src, dtype=str)

uploaded_file = st.file_uploader(
    "Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ñ‚Ðµ Ñ„Ð°Ð¹Ð» Excel Ð°Ð±Ð¾ CSV (Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ðµ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿Ð¸ÑˆÐµ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñ– Ð´Ð°Ð½Ñ–)",
    type=["xlsx", "csv"],
)

DEFAULT_FILE = "data/extracted_data.csv"

if "df" not in st.session_state:
    if uploaded_file:
        st.session_state.df = load_dataframe(uploaded_file)
    elif os.path.exists(DEFAULT_FILE):
        st.session_state.df = load_dataframe(DEFAULT_FILE)
    else:
        st.warning("Ð¡Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ñ‚Ðµ Ð²Ñ…Ñ–Ð´Ð½Ð¸Ð¹ Ñ„Ð°Ð¹Ð».")
        st.stop()

if uploaded_file:
    st.session_state.df = load_dataframe(uploaded_file)

df_raw = st.session_state.df.copy()

df = addColumns(df_raw)

# ----------------------------------------------------------------------------
# 2ï¸âƒ£ ÐŸÐ¾Ð¿ÐµÑ€ÐµÐ´Ð½Ñ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ°
# ----------------------------------------------------------------------------
req_cols = [
    "x_ray_class",
    "peak_flux",
    "lat",
    "lon",
    "duration_minutes",
    "L",
    "date",
]
missing = [c for c in req_cols if c not in df.columns]
if missing:
    st.error("Ð’Ñ–Ð´ÑÑƒÑ‚Ð½Ñ– ÑÑ‚Ð¾Ð²Ð¿Ñ†Ñ–: " + ", ".join(missing))
    st.stop()

# Ð¤Ñ–Ð»ÑŒÑ‚Ñ€ÑƒÑ”Ð¼Ð¾ Ð½Ð° M Ñ‚Ð° X ÐºÐ»Ð°ÑÐ¸ (Ñ‚Ð¾Ð¿Ð¾Ð²Ñ– ÑÐ¿Ð°Ð»Ð°Ñ…Ð¸)
df = df[df["x_ray_class"].isin(["M", "X"])].copy()

# Ð¢Ð¸Ð¿Ð¸ Ð´Ð°Ð½Ð¸Ñ…
num_cols = ["peak_flux", "lat", "lon", "duration_minutes", "L"]
for c in num_cols:
    df[c] = pd.to_numeric(df[c], errors="coerce")

df["date"] = pd.to_datetime(df["date"], errors="coerce")
class_map = {"A": 0, "B": 1, "C": 2, "M": 3, "X": 4}
df["x_ray_class_num"] = df["x_ray_class"].map(class_map)

# ----------------------------------------------------------------------------
# 3ï¸âƒ£ Sidebar â€“ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—
# ----------------------------------------------------------------------------
feature_choices = {
    "x_ray_class_num": "ÐšÐ»Ð°Ñ X-ray (num)",
    "peak_flux": "Peak flux",
    "lat": "Ð¨Ð¸Ñ€Ð¾Ñ‚Ð°",
    "lon": "Ð”Ð¾Ð²Ð³Ð¾Ñ‚Ð°",
    "duration_minutes": "Ð¢Ñ€Ð¸Ð²Ð°Ð»Ñ–ÑÑ‚ÑŒ (Ñ…Ð²)",
    "L": "L",
}

with st.sidebar:
    st.header("âš™ï¸ ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸")
    selected_features = st.multiselect(
        "ÐžÐ·Ð½Ð°ÐºÐ¸", list(feature_choices.values()),
        default=[feature_choices["x_ray_class_num"], feature_choices["peak_flux"], feature_choices["L"]],
    )
    feature_cols = [k for k, v in feature_choices.items() if v in selected_features]

    algo = st.selectbox(
        "ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼",
        (
            "KMeans",
            "DBSCAN",
            # "Agglomerative",
            "Birch",
        ),
    )

    # Ð”Ð¸Ð½Ð°Ð¼Ñ–Ñ‡Ð½Ñ– Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸
    if algo == "KMeans":
        k = st.number_input("K (ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ñ–Ð²)", 2, 15, 3, 1)
    # elif algo == "Agglomerative":
    #     k = st.number_input("ÐšÐ»Ð°ÑÑ‚ÐµÑ€Ñ–Ð²", 2, 15, 3, 1)
    #     linkage = st.selectbox("Linkage", ("ward", "complete", "average", "single"))
    elif algo == "Birch":
        k = st.number_input("ÐšÐ»Ð°ÑÑ‚ÐµÑ€Ñ–Ð²", 2, 15, 3, 1)
        threshold = st.slider("threshold", 0.1, 3.0, 0.5, 0.1)
    else:  # DBSCAN
        eps = st.slider("eps", 0.1, 3.0, 1.2, 0.1)
        min_samples = st.number_input("min_samples", 3, 20, 5, 1)

    run_btn = st.button("ðŸš€ Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸")

if not run_btn:
    st.info("ÐÐ°Ñ‚Ð¸ÑÐ½Ñ–Ñ‚ÑŒ ÐºÐ½Ð¾Ð¿ÐºÑƒ \"Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸\" Ñƒ Ð±Ð¾ÐºÐ¾Ð²Ñ–Ð¹ Ð¿Ð°Ð½ÐµÐ»Ñ–.")
    st.stop()

# ----------------------------------------------------------------------------
# 4ï¸âƒ£ ÐœÐ°Ñ‚Ñ€Ð¸Ñ†Ñ Ð¾Ð·Ð½Ð°Ðº
# ----------------------------------------------------------------------------
df_clu = df.dropna(subset=feature_cols).copy()
if df_clu.empty:
    st.error("ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð½ÑŒÐ¾ Ð´Ð°Ð½Ð¸Ñ… Ð¿Ñ–ÑÐ»Ñ Ð²Ð¸Ð´Ð°Ð»ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÑ–Ð².")
    st.stop()

X = df_clu[feature_cols]
X_scaled = StandardScaler().fit_transform(X)

# ----------------------------------------------------------------------------
# 5ï¸âƒ£ ÐšÐ»Ð°ÑÑ‚ÐµÑ€Ð¸Ð·Ð°Ñ†Ñ–Ñ
# ----------------------------------------------------------------------------
if algo == "KMeans":
    model = KMeans(n_clusters=int(k), random_state=42, n_init="auto")
    labels = model.fit_predict(X_scaled)
elif algo == "DBSCAN":
    model = DBSCAN(eps=float(eps), min_samples=int(min_samples))
    labels = model.fit_predict(X_scaled)
# elif algo == "Agglomerative":
#     model = AgglomerativeClustering(n_clusters=int(k), linkage=linkage)
#     labels = model.fit_predict(X_scaled)
else:  # Birch
    model = Birch(n_clusters=int(k), threshold=threshold)
    labels = model.fit_predict(X_scaled)

# Silhouette (ÐºÐ¾Ð»Ð¸ Ð´Ð¾Ñ€ÐµÑ‡Ð½Ð¾)
unique_lbls = set(labels)
num_clusters = len(unique_lbls) - (1 if -1 in unique_lbls else 0)
if num_clusters > 1:
    sil = silhouette_score(X_scaled, labels)
    st.sidebar.success(f"Silhouette: {sil:.3f}")
else:
    st.sidebar.warning("Silhouette: N/A (â‰¤1 ÐºÐ»Ð°ÑÑ‚ÐµÑ€)")

df_clu["cluster"] = labels.astype(str)

# ----------------------------------------------------------------------------
# 6ï¸âƒ£ Ð’Ñ–Ð·ÑƒÐ°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ–Ð²
# ----------------------------------------------------------------------------

st.subheader("ðŸ“Š")
fig = px.scatter(
    df_clu,
    x='date',
    y='lat',
    color="cluster",
    hover_data=["date", "x_ray_class", "peak_flux", "duration_minutes", "L"],
    title=f"{algo}: {feature_cols[0]} vs {feature_cols[1]}",
)
fig.add_hline(
    y=0,
    line_dash="dash",
    line_color="gray",
    annotation_text="Ð•ÐºÐ²Ð°Ñ‚Ð¾Ñ€",
    annotation_position="top left"
)
fig.update_layout(height=500)
fig.update_traces(marker=dict(line=dict(width=1)))
fig.update_yaxes(title="Ð¨Ð¸Ñ€Ð¾Ñ‚Ð° (Â°)", range=[-90, 90])
st.plotly_chart(fig, use_container_width=True)


# ----------------------------------------------------------------------------
# 7ï¸âƒ£ ÐŸÑ–Ð´ÑÑƒÐ¼ÐºÐ¾Ð²Ð° ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
# ----------------------------------------------------------------------------
st.subheader("ðŸ“‘ Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð°Ñ…")
summary = df_clu.groupby("cluster")[feature_cols].agg(["mean", "std", "count"])
st.markdown('ÐšÐ»Ð°Ñ ÑÐ¿Ð°Ð»Ð°Ñ…Ñƒ - "A": 0, "B": 1, "C": 2, "M": 3, "X": 4')
st.dataframe(summary)
score = silhouette_score(X_scaled, df_clu["cluster"])
st.markdown(f"Silhouette Score: {score:.3f}")

# ----------------------------------------------------------------------------
# 8ï¸âƒ£ Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ–Ð²
# ----------------------------------------------------------------------------
@st.cache_data
def df_to_excel(df_: pd.DataFrame) -> bytes:
    output = BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df_.to_excel(writer, index=False)
    return output.getvalue()

st.download_button(
    label="ðŸ’¾ Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ð¸Ñ‚Ð¸ Excel",
    data=df_to_excel(df_clu),
    file_name="clusters.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)